{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.2426, 4.2426, 4.2426]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 3x3 크기의 텐서 생성\n",
    "x = torch.tensor([[1, 2, 3], \n",
    "                #   [4, 5, 6], \n",
    "                  [7, 8, 9]], dtype=torch.float)\n",
    "\n",
    "# 각 행의 표준 편차 계산\n",
    "# std_per = torch.mean(torch.std(x, dim=0))\n",
    "std_per = torch.std(x, dim=0, keepdim=True)\n",
    "std_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   1,   2,   3,   4,   5,   6],\n",
       "         [  7,   8,   9,  10,  11,  12,  13],\n",
       "         [ 14,  15,  16,  17,  18,  19,  20],\n",
       "         [ 21,  22,  23,  24,  25,  26,  27],\n",
       "         [ 28,  29,  30,  31,  32,  33,  34]],\n",
       "\n",
       "        [[ 35,  36,  37,  38,  39,  40,  41],\n",
       "         [ 42,  43,  44,  45,  46,  47,  48],\n",
       "         [ 49,  50,  51,  52,  53,  54,  55],\n",
       "         [ 56,  57,  58,  59,  60,  61,  62],\n",
       "         [ 63,  64,  65,  66,  67,  68,  69]],\n",
       "\n",
       "        [[ 70,  71,  72,  73,  74,  75,  76],\n",
       "         [ 77,  78,  79,  80,  81,  82,  83],\n",
       "         [ 84,  85,  86,  87,  88,  89,  90],\n",
       "         [ 91,  92,  93,  94,  95,  96,  97],\n",
       "         [ 98,  99, 100, 101, 102, 103, 104]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(3*5*7).view(3, 5, 7)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.tensor([4, 2, 3])\n",
    "t2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "t[t2.unsqueeze(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[28, 29, 30, 31, 32, 33, 34],\n",
      "        [49, 50, 51, 52, 53, 54, 55],\n",
      "        [91, 92, 93, 94, 95, 96, 97]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.arange(3*5*7).view(3, 5, 7)\n",
    "rows = torch.tensor([4, 2, 3])\n",
    "\n",
    "# 각 차원에 대한 인덱스 생성\n",
    "batch_indices = torch.arange(t.size(0))  # 첫 번째 차원(배치 차원)을 위한 인덱스\n",
    "# col_indices = torch.arange(t.size(2))  # 세 번째 차원(열 차원)을 위한 인덱스\n",
    "\n",
    "# 결과 선택\n",
    "selected = t[batch_indices, rows]  # batch_indices와 rows를 사용해 필요한 행을 선택, 모든 열을 포함\n",
    "\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1, 5])\n",
      "tensor([[[[-2.2416, -0.9335, -0.1091, -0.8751,  1.7017],\n",
      "          [-0.9493,  0.6737,  1.0425,  1.6600, -0.8463],\n",
      "          [ 0.6690, -1.1850,  1.3416,  0.6131, -1.7261],\n",
      "          [-1.2091,  0.4820,  1.4052,  1.5463,  1.2900]],\n",
      "\n",
      "         [[ 0.0080,  0.6296,  1.1523, -1.7720, -0.8275],\n",
      "          [-0.4476,  1.0355, -0.9121,  0.9403, -1.5383],\n",
      "          [ 1.9812,  0.1521,  1.0496, -0.3971,  1.6726],\n",
      "          [-0.7889, -0.2200,  0.6852,  0.9636,  1.6826]],\n",
      "\n",
      "         [[-0.0222, -1.1725,  0.0880, -0.3017,  0.0338],\n",
      "          [-0.2303, -0.4895, -1.9712, -1.0895,  1.4418],\n",
      "          [ 0.5153,  0.0586, -1.6305,  0.3750, -0.6582],\n",
      "          [-1.2648,  0.0697, -0.3617, -0.9210, -0.1959]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4013,  0.0548,  1.0281, -0.8447,  0.1573],\n",
      "          [-0.1847,  0.9468, -0.0571,  1.1472,  2.3481],\n",
      "          [-1.5240,  0.8287,  1.4842, -0.7634,  2.0313],\n",
      "          [-0.8925,  0.1698, -0.5042,  0.1865, -0.8488]],\n",
      "\n",
      "         [[-0.7752,  0.0194, -0.7373,  1.3206, -0.0333],\n",
      "          [ 1.5254, -0.9745,  1.0650,  0.2300,  0.6017],\n",
      "          [-1.9354, -0.4881, -0.0301,  0.9853, -0.7174],\n",
      "          [-0.9578,  0.2294, -0.5831, -0.6748,  0.2301]],\n",
      "\n",
      "         [[ 0.7912, -1.0363, -0.9951,  1.1318,  0.4847],\n",
      "          [ 0.7445, -0.0259,  0.0549,  1.3313,  0.4903],\n",
      "          [-0.4955,  0.6317,  0.3548,  0.5330,  1.0343],\n",
      "          [ 0.1159,  2.2298,  0.8804, -0.1208, -0.4845]]]])\n",
      "tensor([[[[-1.2091,  0.4820,  1.4052,  1.5463,  1.2900]],\n",
      "\n",
      "         [[-0.4476,  1.0355, -0.9121,  0.9403, -1.5383]],\n",
      "\n",
      "         [[-0.2303, -0.4895, -1.9712, -1.0895,  1.4418]]],\n",
      "\n",
      "\n",
      "        [[[-0.1847,  0.9468, -0.0571,  1.1472,  2.3481]],\n",
      "\n",
      "         [[ 1.5254, -0.9745,  1.0650,  0.2300,  0.6017]],\n",
      "\n",
      "         [[ 0.7912, -1.0363, -0.9951,  1.1318,  0.4847]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# [3, 10, 32, 256] 크기의 텐서 생성\n",
    "x = torch.randn(2, 3, 4, 5)\n",
    "\n",
    "# [3, 10] 크기의 인덱스 텐서 생성, 예를 들어 여기서는 32보다 작은 임의의 정수를 선택\n",
    "indices = torch.randint(0, 4, (2, 3))\n",
    "\n",
    "# 인덱스 텐서의 크기를 조정하여 gather에 사용할 수 있도록 함\n",
    "# 여기서는 세 번째 차원(인덱스 2)에서 요소를 선택하고자 하므로, 인덱스 텐서의 크기를 [3, 10, 1, 1]로 조정합니다.\n",
    "indices = indices.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, -1, 5)\n",
    "\n",
    "# torch.gather를 사용하여 원하는 요소 선택\n",
    "# dim=2는 세 번째 차원에서 인덱싱을 수행하겠다는 것을 의미합니다.\n",
    "result = torch.gather(x, 2, indices)\n",
    "\n",
    "print(result.shape)  # 결과적으로 [3, 10, 1, 256] 크기의 텐서를 얻습니다.\n",
    "\n",
    "print(x)\n",
    "print(result)\n",
    "torch.isnan(result).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0,   1,   2,   3,   4],\n",
       "          [  5,   6,   7,   8,   9],\n",
       "          [ 10,  11,  12,  13,  14],\n",
       "          [ 15,  16,  17,  18,  19]],\n",
       "\n",
       "         [[ 20,  21,  22,  23,  24],\n",
       "          [ 25,  26,  27,  28,  29],\n",
       "          [ 30,  31,  32,  33,  34],\n",
       "          [ 35,  36,  37,  38,  39]],\n",
       "\n",
       "         [[ 40,  41,  42,  43,  44],\n",
       "          [ 45,  46,  47,  48,  49],\n",
       "          [ 50,  51,  52,  53,  54],\n",
       "          [ 55,  56,  57,  58,  59]]],\n",
       "\n",
       "\n",
       "        [[[ 60,  61,  62,  63,  64],\n",
       "          [ 65,  66,  67,  68,  69],\n",
       "          [ 70,  71,  72,  73,  74],\n",
       "          [ 75,  76,  77,  78,  79]],\n",
       "\n",
       "         [[ 80,  81,  82,  83,  84],\n",
       "          [ 85,  86,  87,  88,  89],\n",
       "          [ 90,  91,  92,  93,  94],\n",
       "          [ 95,  96,  97,  98,  99]],\n",
       "\n",
       "         [[100, 101, 102, 103, 104],\n",
       "          [105, 106, 107, 108, 109],\n",
       "          [110, 111, 112, 113, 114],\n",
       "          [115, 116, 117, 118, 119]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [3, 10, 32, 256] 크기의 텐서 생성\n",
    "x = torch.arange(2 * 3 * 4 * 5).view(2, 3, 4, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0, 1],\n",
       "        [2, 2, 2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# [3, 10] 크기의 인덱스 텐서 생성, 예를 들어 여기서는 32보다 작은 임의의 정수를 선택\n",
    "indices = torch.randint(0, 3, (2, 3))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2, 2, 2, 2, 2]],\n",
       "\n",
       "         [[0, 0, 0, 0, 0]],\n",
       "\n",
       "         [[1, 1, 1, 1, 1]]],\n",
       "\n",
       "\n",
       "        [[[2, 2, 2, 2, 2]],\n",
       "\n",
       "         [[2, 2, 2, 2, 2]],\n",
       "\n",
       "         [[2, 2, 2, 2, 2]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 인덱스 텐서의 크기를 조정하여 gather에 사용할 수 있도록 함\n",
    "# 여기서는 세 번째 차원(인덱스 2)에서 요소를 선택하고자 하므로, 인덱스 텐서의 크기를 [3, 10, 1, 1]로 조정합니다.\n",
    "indices = indices.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, -1, 5)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 10,  11,  12,  13,  14]],\n",
       "\n",
       "         [[ 20,  21,  22,  23,  24]],\n",
       "\n",
       "         [[ 45,  46,  47,  48,  49]]],\n",
       "\n",
       "\n",
       "        [[[ 70,  71,  72,  73,  74]],\n",
       "\n",
       "         [[ 90,  91,  92,  93,  94]],\n",
       "\n",
       "         [[110, 111, 112, 113, 114]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# torch.gather를 사용하여 원하는 요소 선택\n",
    "# dim=2는 세 번째 차원에서 인덱싱을 수행하겠다는 것을 의미합니다.\n",
    "result = torch.gather(x, 2, indices)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(result.shape)  # 결과적으로 [3, 10, 1, 256] 크기의 텐서를 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 40,  41,  42,  43,  44]],\n",
       "\n",
       "         [[  0,   1,   2,   3,   4]],\n",
       "\n",
       "         [[ 20,  21,  22,  23,  24]]],\n",
       "\n",
       "\n",
       "        [[[100, 101, 102, 103, 104]],\n",
       "\n",
       "         [[100, 101, 102, 103, 104]],\n",
       "\n",
       "         [[100, 101, 102, 103, 104]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(x, 1, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(2 * 3).view(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.randint(0, 2, (2, ))\n",
    "indices = indices.unsqueeze(-1).expand(-1, 3)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [3, 3, 3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(x, 1, indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prepro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
